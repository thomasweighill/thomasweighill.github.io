<div class="subsection" id="subsection-PMM" acro="PMM" titletext="Properties of Matrix Multiplication">
<h4 class="subsection">
<span class="type">Subsection</span> <span class="acro">PMM</span> <span class="titletext">Properties of Matrix Multiplication</span>
</h4>
<p>In this subsection, we collect properties of matrix multiplication and its interaction with
the zero matrix (<a class="knowl" acro="ZM" type="Definition" title="Zero Matrix" knowl="./knowls/definition.ZM.knowl">Definition ZM</a>),
the identity matrix (<a class="knowl" acro="IM" type="Definition" title="Identity Matrix" knowl="./knowls/definition.IM.knowl">Definition IM</a>),
matrix addition (<a class="knowl" acro="MA" type="Definition" title="Matrix Addition" knowl="./knowls/definition.MA.knowl">Definition MA</a>),
scalar matrix multiplication (<a class="knowl" acro="MSM" type="Definition" title="Matrix Scalar Multiplication" knowl="./knowls/definition.MSM.knowl">Definition MSM</a>),
the inner product (<a class="knowl" acro="IP" type="Definition" title="Inner Product" knowl="./knowls/definition.IP.knowl">Definition IP</a>),
conjugation (<a class="knowl" acro="MMCC" type="Theorem" title="Matrix Multiplication and Complex Conjugation" knowl="./knowls/theorem.MMCC.knowl">Theorem MMCC</a>),
and
the transpose (<a class="knowl" acro="TM" type="Definition" title="Transpose of a Matrix" knowl="./knowls/definition.TM.knowl">Definition TM</a>).
Whew!  Here we go.  These are great proofs to practice with, so try to concoct the proofs before reading them, they will get progressively more complicated as we go.</p>
<div class="theorem" id="theorem-MMZM" acro="MMZM" titletext="Matrix Multiplication and the Zero Matrix">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">MMZM</span><span class="titletext"> Matrix Multiplication and the Zero Matrix</span>
</h5>
<div class="statement"><p>Suppose $A$ is an $m\times n$ matrix.  Then
<ol>
<li> $A\zeromatrix_{n\times p}=\zeromatrix_{m\times p}$
</li>
<li> $\zeromatrix_{p\times m}A=\zeromatrix_{p\times n}$
</li>
</ol>
</p></div>
<div class="proof"><a knowl="./knowls/proof.MMZM.knowl">Proof</a></div>
</div>
<div class="theorem" id="theorem-MMIM" acro="MMIM" titletext="Matrix Multiplication and Identity Matrix">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">MMIM</span><span class="titletext"> Matrix Multiplication and Identity Matrix</span>
</h5>
<div class="statement"><p>Suppose $A$ is an $m\times n$ matrix.  Then
<ol>
<li> $AI_n=A$
</li>
<li> $I_mA=A$
</li>
</ol>
</p></div>
<div class="proof"><a knowl="./knowls/proof.MMIM.knowl">Proof</a></div>
</div>
<p>It is this theorem that gives the identity matrix its name.  It is a matrix that behaves with matrix multiplication like the scalar 1 does with scalar multiplication.  To multiply by the identity matrix is to have no effect on the other matrix.</p>
<div class="theorem" id="theorem-MMDAA" acro="MMDAA" titletext="Matrix Multiplication Distributes Across Addition">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">MMDAA</span><span class="titletext"> Matrix Multiplication Distributes Across Addition</span>
</h5>
<div class="statement"><p>Suppose $A$ is an $m\times n$ matrix and $B$ and $C$ are $n\times p$ matrices and $D$ is a $p\times s$ matrix.    Then
<ol>
<li> $A(B+C)=AB+AC$
</li>
<li> $(B+C)D=BD+CD$
</li>
</ol>
</p></div>
<div class="proof"><a knowl="./knowls/proof.MMDAA.knowl">Proof</a></div>
</div>
<div class="theorem" id="theorem-MMSMM" acro="MMSMM" titletext="Matrix Multiplication and Scalar Matrix Multiplication">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">MMSMM</span><span class="titletext"> Matrix Multiplication and Scalar Matrix Multiplication</span>
</h5>
<div class="statement"><p>Suppose $A$ is an $m\times n$ matrix and $B$ is an $n\times p$ matrix.  Let $\alpha$ be a scalar.  Then $\alpha(AB)=(\alpha A)B=A(\alpha B)$.</p></div>
<div class="proof"><a knowl="./knowls/proof.MMSMM.knowl">Proof</a></div>
</div>
<div class="theorem" id="theorem-MMA" acro="MMA" titletext="Matrix Multiplication is Associative">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">MMA</span><span class="titletext"> Matrix Multiplication is Associative</span>
</h5>
<div class="statement"><p>Suppose $A$ is an $m\times n$ matrix, $B$ is an $n\times p$ matrix and $D$ is a $p\times s$ matrix.  Then  $A(BD)=(AB)D$.</p></div>
<div class="proof"><a knowl="./knowls/proof.MMA.knowl">Proof</a></div>
</div>
<p>Since <a class="knowl" acro="MMA" type="Theorem" title="Matrix Multiplication is Associative" knowl="./knowls/theorem.MMA.knowl">Theorem MMA</a> says matrix multipication is associative, it means we do not have to be careful about the order in which we perform matrix multiplication, nor how we parenthesize an expression with just several matrices multiplied togther.  So this is where we draw the line on explaining every last detail in a proof.  We will frequently add, remove, or rearrange parentheses with no comment.  Indeed, I only see about a dozen places where <a class="knowl" acro="MMA" type="Theorem" title="Matrix Multiplication is Associative" knowl="./knowls/theorem.MMA.knowl">Theorem MMA</a> is cited in a proof.  You could try to count how many times we <em>avoid</em> making a reference to this theorem.</p>
<p>The statement of our next theorem is technically inaccurate.  If we upgrade the vectors $\vect{u},\,\vect{v}$ to matrices with a single column, then the expression $\transpose{\conjugate{\vect{u}}}\vect{v}$ is a $1\times 1$ matrix, though we will treat this small matrix as if it was simply the scalar quantity in its lone entry.  When we apply <a class="knowl" acro="MMIP" type="Theorem" title="Matrix Multiplication and Inner Products" knowl="./knowls/theorem.MMIP.knowl">Theorem MMIP</a> there should not be any confusion.  Notice that if we treat a column vector as a matrix with a single column, then we can also construct the adjoint of a vector, though we will not make this a common practice.</p>
<div class="theorem" id="theorem-MMIP" acro="MMIP" titletext="Matrix Multiplication and Inner Products">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">MMIP</span><span class="titletext"> Matrix Multiplication and Inner Products</span>
</h5>
<div class="statement"><p>If we consider the vectors $\vect{u},\,\vect{v}\in\complex{m}$ as $m\times 1$ matrices then
\begin{align*}
\innerproduct{\vect{u}}{\vect{v}}
&amp;=\transpose{\conjugate{\vect{u}}}\vect{v}
=\adjoint{\vect{u}}\vect{v}
\end{align*}

</p></div>
<div class="proof"><a knowl="./knowls/proof.MMIP.knowl">Proof</a></div>
</div>
<div class="theorem" id="theorem-MMCC" acro="MMCC" titletext="Matrix Multiplication and Complex Conjugation">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">MMCC</span><span class="titletext"> Matrix Multiplication and Complex Conjugation</span>
</h5>
<div class="statement"><p>Suppose $A$ is an $m\times n$ matrix and $B$ is an $n\times p$ matrix.  Then $\conjugate{AB}=\conjugate{A}\,\conjugate{B}$.</p></div>
<div class="proof"><a knowl="./knowls/proof.MMCC.knowl">Proof</a></div>
</div>
<p>Another theorem in this style, and it is a good one.  If you have been practicing with the previous proofs you should be able to do this one yourself.</p>
<div class="theorem" id="theorem-MMT" acro="MMT" titletext="Matrix Multiplication and Transposes">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">MMT</span><span class="titletext"> Matrix Multiplication and Transposes</span>
</h5>
<div class="statement"><p>Suppose $A$ is an $m\times n$ matrix and $B$ is an $n\times p$ matrix.  Then $\transpose{(AB)}=\transpose{B}\transpose{A}$.</p></div>
<div class="proof"><a knowl="./knowls/proof.MMT.knowl">Proof</a></div>
</div>
<p>This theorem seems odd at first glance, since we have to switch the order of $A$ and $B$.  But if we simply consider the sizes of the matrices involved, we can see that the switch is necessary for this reason alone.  That the individual entries of the products then come along to be equal is a bonus.</p>
<p>As the adjoint of a matrix is a composition of a conjugate and a transpose, its interaction with matrix multiplication is similar to that of a transpose.  Here is the last of our long list of basic properties of matrix multiplication.</p>
<div class="theorem" id="theorem-MMAD" acro="MMAD" titletext="Matrix Multiplication and Adjoints">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">MMAD</span><span class="titletext"> Matrix Multiplication and Adjoints</span>
</h5>
<div class="statement"><p>Suppose $A$ is an $m\times n$ matrix and $B$ is an $n\times p$ matrix.  Then $\adjoint{(AB)}=\adjoint{B}\adjoint{A}$.</p></div>
<div class="proof"><a knowl="./knowls/proof.MMAD.knowl">Proof</a></div>
</div>
<p>Notice how none of these proofs above relied on writing out huge general matrices with lots of ellipses (“…”) and trying to formulate the equalities a whole matrix at a time.  This messy business is a “proof technique” to be avoided at all costs.  Notice too how the proof of <a class="knowl" acro="MMAD" type="Theorem" title="Matrix Multiplication and Adjoints" knowl="./knowls/theorem.MMAD.knowl">Theorem MMAD</a> does not use an entry-by-entry approach, but simply builds on previous results about matrix multiplication's interaction with conjugation and transposes.</p>
<p>These theorems, along with <a class="knowl" acro="VSPM" type="Theorem" title="Vector Space Properties of Matrices" knowl="./knowls/theorem.VSPM.knowl">Theorem VSPM</a> and the other results in <a href="section-MO.html" title="Matrix Operations">Section MO</a>, give you the “rules” for how matrices interact with the various operations we have defined on matrices (addition, scalar multiplication, matrix multiplication, conjugation, transposes and adjoints).  Use them and use them often.  But do not try to do anything with a matrix that you do not have a rule for.  Together, we would informally call all these operations, and the attendant theorems, “the algebra of matrices.”  Notice, too, that every column vector is just a $n\times 1$ matrix, so these theorems apply to column vectors also.  Finally, these results, taken as a whole, may make us feel that the definition of matrix multiplication is not so unnatural.</p>
<div class="sage" id="sage-PMM" acro="PMM" titletext="Properties of Matrix Multiplication"><h5 class="sage">
<a knowl="./knowls/sage.PMM.knowl"><span class="type">Sage</span> <span class="acro">PMM</span></a> <span class="titletext">Properties of Matrix Multiplication</span>
</h5></div>
</div><div class="context"><a href="http://linear.pugetsound.edu/html/section-MM.html#subsection-PMM" class="context" title="Section MM">(in context)</a></div>
