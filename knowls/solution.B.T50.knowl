<div class="solution" acro="B.T50">
<h5 class="solution">
<span class="type">Solution</span> <span class="acro">B.T50</span> <span class="contributor"><a knowl="./knowls/contributor.robertbeezer.knowl">Robert Beezer</a></span>
</h5>Our first proof relies mostly on definitions of linear independence and spanning, which is a good exercise.  The second proof is shorter and turns on a technical result from our work with matrix inverses, <a class="knowl" acro="NPNT" type="Theorem" title="Nonsingular Product has Nonsingular Terms" knowl="./knowls/theorem.NPNT.knowl">Theorem NPNT</a>.<br><br>
(⇒)  Assume that $A$ is nonsingular and prove that $C$ is a basis of $\complex{n}$.  First show that $C$ is linearly independent.  Work on a relation of linear dependence on $C$,
\begin{align*}
\zerovector
&amp;=
a_1A\vect{x}_1+
a_2A\vect{x}_2+
a_3A\vect{x}_3+
\cdots+
a_nA\vect{x}_n
&amp;&amp;\knowl{./knowls/definition.RLD.knowl}{\text{Definition RLD}}\\
&amp;=
Aa_1\vect{x}_1+
Aa_2\vect{x}_2+
Aa_3\vect{x}_3+
\cdots+
Aa_n\vect{x}_n
&amp;&amp;\knowl{./knowls/theorem.MMSMM.knowl}{\text{Theorem MMSMM}}\\
&amp;=
A\left(
a_1\vect{x}_1+
a_2\vect{x}_2+
a_3\vect{x}_3+
\cdots+
a_n\vect{x}_n
\right)
&amp;&amp;\knowl{./knowls/theorem.MMDAA.knowl}{\text{Theorem MMDAA}}
\end{align*}

Since $A$ is nonsingular, <a class="knowl" acro="NM" type="Definition" title="Nonsingular Matrix" knowl="./knowls/definition.NM.knowl">Definition NM</a> and <a class="knowl" acro="SLEMM" type="Theorem" title="Systems of Linear Equations as Matrix Multiplication" knowl="./knowls/theorem.SLEMM.knowl">Theorem SLEMM</a> allows us to conclude that
\begin{align*}
a_1\vect{x}_1+
a_2\vect{x}_2+
\cdots+
a_n\vect{x}_n
&amp;=\zerovector
\end{align*}

But this is a relation of linear dependence of the linearly independent set $B$, so the scalars are trivial, $a_1=a_2=a_3=\cdots=a_n=0$.  By <a class="knowl" acro="LI" type="Definition" title="Linear Independence" knowl="./knowls/definition.LI.knowl">Definition LI</a>, the set $C$ is linearly independent.<br><br>
Now prove that $C$ spans $\complex{n}$.  Given an arbitrary vector $\vect{y}\in\complex{n}$, can it be expressed as a linear combination of the vectors in $C$?  Since $A$ is a nonsingular matrix we can define the vector $\vect{w}$ to be the unique solution of the system $\linearsystem{A}{\vect{y}}$ (<a class="knowl" acro="NMUS" type="Theorem" title="Nonsingular Matrices and Unique Solutions" knowl="./knowls/theorem.NMUS.knowl">Theorem NMUS</a>).  Since $\vect{w}\in\complex{n}$ we can write $\vect{w}$ as a linear combination of the vectors in the basis $B$.  So there are scalars, $\scalarlist{b}{n}$ such that
\begin{align*}
\vect{w}&amp;=\lincombo{b}{x}{n}
\end{align*}

Then,
\begin{align*}
\vect{y}
&amp;=A\vect{w}
&amp;&amp;\knowl{./knowls/theorem.SLEMM.knowl}{\text{Theorem SLEMM}}\\
&amp;=A\left(\lincombo{b}{x}{n}\right)
&amp;&amp;\knowl{./knowls/definition.SSVS.knowl}{\text{Definition SSVS}}\\
&amp;=
Ab_1\vect{x}_1+
Ab_2\vect{x}_2+
Ab_3\vect{x}_3+
\cdots+
Ab_n\vect{x}_n
&amp;&amp;\knowl{./knowls/theorem.MMDAA.knowl}{\text{Theorem MMDAA}}\\
&amp;=
b_1A\vect{x}_1+
b_2A\vect{x}_2+
b_3A\vect{x}_3+
\cdots+
b_nA\vect{x}_n
&amp;&amp;\knowl{./knowls/theorem.MMSMM.knowl}{\text{Theorem MMSMM}}
\end{align*}

So we can write an arbitrary vector of $\complex{n}$ as a linear combination of the elements of $C$.  In other words, $C$ spans $\complex{n}$ (<a class="knowl" acro="SSVS" type="Definition" title="Spanning Set of a Vector Space" knowl="./knowls/definition.SSVS.knowl">Definition SSVS</a>).  By <a class="knowl" acro="B" type="Definition" title="Basis" knowl="./knowls/definition.B.knowl">Definition B</a>, the set $C$ is a basis for $\complex{n}$.<br><br>
(⇐) Assume that $C$ is a basis and prove that $A$ is nonsingular.  Let $\vect{x}$ be a solution to the homogeneous system $\homosystem{A}$.  Since $B$ is a basis of $\complex{n}$ there are  scalars, $\scalarlist{a}{n}$, such that
\begin{align*}
\vect{x}&amp;=\lincombo{a}{x}{n}
\end{align*}

Then
\begin{align*}
\zerovector
&amp;=A\vect{x}
&amp;&amp;\knowl{./knowls/theorem.SLEMM.knowl}{\text{Theorem SLEMM}}\\
&amp;=A\left(\lincombo{a}{x}{n}\right)
&amp;&amp;\knowl{./knowls/definition.SSVS.knowl}{\text{Definition SSVS}}\\
&amp;=
Aa_1\vect{x}_1+
Aa_2\vect{x}_2+
Aa_3\vect{x}_3+
\cdots+
Aa_n\vect{x}_n
&amp;&amp;\knowl{./knowls/theorem.MMDAA.knowl}{\text{Theorem MMDAA}}\\
&amp;=
a_1A\vect{x}_1+
a_2A\vect{x}_2+
a_3A\vect{x}_3+
\cdots+
a_nA\vect{x}_n
&amp;&amp;\knowl{./knowls/theorem.MMSMM.knowl}{\text{Theorem MMSMM}}
\end{align*}

This is a relation of linear dependence on the linearly independent set $C$, so the scalars must all be zero, $a_1=a_2=a_3=\cdots=a_n=0$.  Thus,
\begin{align*}
\vect{x}&amp;=\lincombo{a}{x}{n}=0\vect{x}_1+0\vect{x}_2+0\vect{x}_3+\cdots+0\vect{x}_n=\zerovector.
\end{align*}

By <a class="knowl" acro="NM" type="Definition" title="Nonsingular Matrix" knowl="./knowls/definition.NM.knowl">Definition NM</a> we see that $A$ is nonsingular.<br><br>
Now for a second proof.  Take the vectors for $B$ and use them as the columns of a matrix, $G=\matrixcolumns{x}{n}$.  By <a class="knowl" acro="CNMB" type="Theorem" title="Columns of Nonsingular Matrix are a Basis" knowl="./knowls/theorem.CNMB.knowl">Theorem CNMB</a>, because we have the hypothesis that $B$ is a basis of $\complex{n}$, $G$ is a nonsingular matrix.  Notice that the columns of $AG$ are exactly the vectors in the set $C$, by <a class="knowl" acro="MM" type="Definition" title="Matrix Multiplication" knowl="./knowls/definition.MM.knowl">Definition MM</a>.
\begin{align*}
A\text{ nonsingular}
&amp;\iff AG\text{ nonsingular}
&amp;&amp;\knowl{./knowls/theorem.NPNT.knowl}{\text{Theorem NPNT}}\\
&amp;\iff C\text{ basis for }\complex{n}
&amp;&amp;\knowl{./knowls/theorem.CNMB.knowl}{\text{Theorem CNMB}}\\
\end{align*}

That was easy!
</div>
