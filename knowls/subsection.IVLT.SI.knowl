<div class="subsection" id="subsection-SI" acro="SI" titletext="Structure and Isomorphism">
<h4 class="subsection">
<span class="type">Subsection</span> <span class="acro">SI</span> <span class="titletext">Structure and Isomorphism</span>
</h4>
<p>A vector space is defined (<a class="knowl" acro="VS" type="Definition" title="Vector Space" knowl="./knowls/definition.VS.knowl">Definition VS</a>) as a set of objects (“vectors”) endowed with a definition of vector addition ($+$) and a definition of scalar multiplication (written with juxtaposition).  Many of our definitions about vector spaces involve linear combinations (<a class="knowl" acro="LC" type="Definition" title="Linear Combination" knowl="./knowls/definition.LC.knowl">Definition LC</a>), such as the span of a set (<a class="knowl" acro="SS" type="Definition" title="Span of a Set" knowl="./knowls/definition.SS.knowl">Definition SS</a>) and linear independence (<a class="knowl" acro="LI" type="Definition" title="Linear Independence" knowl="./knowls/definition.LI.knowl">Definition LI</a>).  Other definitions are built up from these ideas, such as bases (<a class="knowl" acro="B" type="Definition" title="Basis" knowl="./knowls/definition.B.knowl">Definition B</a>) and dimension (<a class="knowl" acro="D" type="Definition" title="Dimension" knowl="./knowls/definition.D.knowl">Definition D</a>).  The defining properties of a linear transformation require that a function “respect” the operations of the two vector spaces that are the domain and the codomain (<a class="knowl" acro="LT" type="Definition" title="Linear Transformation" knowl="./knowls/definition.LT.knowl">Definition LT</a>).  Finally, an invertible linear transformation is one that can be “undone” — it has a companion that reverses its effect.  In this subsection we are going to begin to roll all these ideas into one.</p>
<p>A vector space has “structure” derived from definitions of the two operations and the requirement that these operations interact in ways that satisfy the ten properties of <a class="knowl" acro="VS" type="Definition" title="Vector Space" knowl="./knowls/definition.VS.knowl">Definition VS</a>.  When two different vector spaces have an invertible linear transformation defined between them, then we can translate questions about linear combinations (spans, linear independence, bases, dimension) from the first vector space to the second.  The answers obtained in the second vector space can then be translated back, via the inverse linear transformation, and interpreted in the setting of the first vector space.  We say that these invertible linear transformations “preserve structure.”  And we say that the two vector spaces are “structurally the same.”  The precise term is “isomorphic,” from Greek meaning “of the same form.”  Let us begin to try to understand this important concept.</p>
<div class="definition" id="definition-IVS" acro="IVS" titletext="Isomorphic Vector Spaces">
<h5 class="definition">
<span class="type">Definition </span><span class="acro">IVS</span> <span class="titletext"> Isomorphic Vector Spaces</span>
</h5>
<p>Two vector spaces $U$ and $V$ are <em class="term">isomorphic</em> if there exists an invertible linear transformation $T$ with domain $U$ and codomain $V$, $\ltdefn{T}{U}{V}$.  In this case, we write $U\isomorphic V$, and the linear transformation $T$ is known as an <em class="term">isomorphism</em> between $U$ and $V$.</p>
</div>
<p>A few comments on this definition.  First, be careful with your language (<a class="knowl" acro="L" type="Proof Technique" title="Language" knowl="./knowls/technique.L.knowl">Proof Technique L</a>).  Two vector spaces are isomorphic, or not.  It is a yes/no situation and the term only applies to a pair of vector spaces.  Any invertible linear transformation can be called an isomorphism, it is a term that applies to functions.  Second, given a pair of vector spaces there might be several different isomorphisms between the two vector spaces.  But it only takes the existence of one to call the pair isomorphic.  Third,  $U$ isomorphic to $V$, or $V$ isomorphic to $U$?  It does not matter, since the inverse linear transformation will provide the needed isomorphism in the “opposite” direction.  Being “isomorphic to” is an equivalence relation on the set of all vector spaces (see <a class="knowl" acro="SER" type="Theorem" title="Similarity is an Equivalence Relation" knowl="./knowls/theorem.SER.knowl">Theorem SER</a> for a reminder about equivalence relations).</p>
<div class="example" id="example-IVSAV" acro="IVSAV" titletext="Isomorphic vector spaces, Archetype V"><h5 class="example">
<a knowl="./knowls/example.IVSAV.knowl"><span class="type">Example</span> <span class="acro">IVSAV</span></a> <span class="titletext">Isomorphic vector spaces, Archetype V</span>
</h5></div>
<p>In <a class="knowl" acro="IVSAV" type="Example" title="Isomorphic vector spaces, Archetype V" knowl="./knowls/example.IVSAV.knowl">Example IVSAV</a> we avoided a computation in $P_3$ by a conversion of the computation to a new vector space, $M_{22}$, via an invertible linear transformation (also known as an isomorphism).  Here is a diagram meant to illustrate the more general situation of two vector spaces, $U$ and $V$, and an invertible linear transformation, $T$.  The diagram is simply about a sum of two vectors from $U$, rather than a more involved linear combination.  It should remind you of <a class="knowl" acro="DLTA" type="Diagram" title="Definition of Linear Transformation, Additive" knowl="./knowls/diagram.DLTA.knowl">Diagram DLTA</a>.
<div class="diagram" id="diagram-AIVS" acro="AIVS" titletext="Addition in Isomorphic Vector Spaces">
<a id="diagram-AIVS"></a><object type="image/svg+xml" data="./diagrams/AIVS.svg">SVG image not dispayed</object><br><br><h5 class="diagram">
<span class="type">Diagram</span> <span class="acro">AIVS</span> <span class="titletext">Addition in Isomorphic Vector Spaces</span>
</h5>
</div>
To understand this diagram, begin in the upper-left corner, and by going straight down we can compute the sum of the two vectors using the addition for the vector space $U$.  The more circuitous alternative, in the spirit of <a class="knowl" acro="IVSAV" type="Example" title="Isomorphic vector spaces, Archetype V" knowl="./knowls/example.IVSAV.knowl">Example IVSAV</a>, is to begin in the upper-left corner and then proceed clockwise around the other three sides of the rectangle.  Notice that the vector addition is accomplished using the addition in the vector space $V$.  Then, because $T$ is a linear transformation, we can say that the result of $\lt{T}{\vect{u}_1}+\lt{T}{\vect{u}_2}$ is  equal to $\lt{T}{\vect{u}_1+\vect{u}_2}$.  Then the key feature is to recognize that applying $\ltinverse{T}$ obviously converts the second version of this result into the sum in the lower-left corner.  So there are two routes to the sum $\vect{u}_1+\vect{u}_2$, each employing an addition from a different vector space, but one is “direct” and the other is “roundabout”.  You might try designing a similar diagram for the case of scalar multiplication (see <a class="knowl" acro="DLTM" type="Diagram" title="Definition of Linear Transformation, Multiplicative" knowl="./knowls/diagram.DLTM.knowl">Diagram DLTM</a>) or for a full linear combination.</p>
<p>Checking the dimensions of two vector spaces can be a quick way to establish that they are not isomorphic.  Here is the theorem.</p>
<div class="theorem" id="theorem-IVSED" acro="IVSED" titletext="Isomorphic Vector Spaces have Equal Dimension">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">IVSED</span><span class="titletext"> Isomorphic Vector Spaces have Equal Dimension</span>
</h5>
<div class="statement"><p>Suppose $U$ and $V$ are isomorphic vector spaces.  Then $\dimension{U}=\dimension{V}$.</p></div>
<div class="proof"><a knowl="./knowls/proof.IVSED.knowl">Proof</a></div>
</div>
<p>The contrapositive of <a class="knowl" acro="IVSED" type="Theorem" title="Isomorphic Vector Spaces have Equal Dimension" knowl="./knowls/theorem.IVSED.knowl">Theorem IVSED</a> says that if $U$ and $V$ have different dimensions, then they are not isomorphic.  Dimension is the simplest “structural” characteristic that will allow you to distinguish non-isomorphic vector spaces.  For example $P_6$ is not isomorphic to $M_{34}$ since their dimensions (7 and 12, respectively) are not equal.  With tools developed in <a href="section-VR.html" title="Vector Representations">Section VR</a> we will be able to establish that the converse of <a class="knowl" acro="IVSED" type="Theorem" title="Isomorphic Vector Spaces have Equal Dimension" knowl="./knowls/theorem.IVSED.knowl">Theorem IVSED</a> is true.  Think about that one for a moment.</p>
</div><div class="context"><a href="http://linear.pugetsound.edu/html/section-IVLT.html#subsection-SI" class="context" title="Section IVLT">(in context)</a></div>
