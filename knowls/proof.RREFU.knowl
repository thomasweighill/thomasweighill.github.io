<div class="proof" id="proof-RREFU" acro="RREFU" titletext="">
<h5 class="proof">
<span class="type">Proof of Theorem</span> <span class="acro">RREFU</span>
</h5>
<p>We need to begin with no assumptions about any relationships between $B$ and $C$, other than they are both in reduced row-echelon form, and they are both row-equivalent to $A$.</p>

<p>If $B$ and $C$ are both row-equivalent to $A$, then they are row-equivalent to each other.  Repeated row operations on a matrix combine the rows with each other using operations that are linear, and are identical in each column.  A key observation for this proof is that each individual row of $B$ is linearly related to the rows of $C$.  This relationship is different for each row of $B$, but once we fix a row, the relationship is the same across columns.  More precisely, there are scalars $\delta_{ik}$, $1\leq i,k\leq m$ such that for any $1\leq i\leq m$, $1\leq j\leq n$,
\begin{align*}
\matrixentry{B}{ij}
&amp;=\sum_{k=1}^{m}\delta_{ik}\matrixentry{C}{kj}
\end{align*}
</p>

<p>You should read this as saying that an entry of row $i$ of $B$ (in column $j$) is a linear function of the entries of all the rows of $C$ that are also in column $j$, and the scalars ($\delta_{ik}$) depend on which row of $B$ we are considering (the $i$ subscript on $\delta_{ik}$), but are the same for every column (no dependence on $j$ in $\delta_{ik}$).  This idea may be complicated now, but will feel more familiar once we discuss “linear combinations” (<a class="knowl" acro="LCCV" type="Definition" title="Linear Combination of Column Vectors" knowl="./knowls/definition.LCCV.knowl">Definition LCCV</a>) and moreso when we discuss “row spaces” (<a class="knowl" acro="RSM" type="Definition" title="Row Space of a Matrix" knowl="./knowls/definition.RSM.knowl">Definition RSM</a>).  For now, spend some time carefully working <a knowl="./knowls/exercise.RREF.M40.knowl">Exercise RREF.M40</a>, which is designed to illustrate the origins of this expression.  This completes our exploitation of the row-equivalence of $B$ and $C$.</p>

<p>We now repeatedly exploit the fact that $B$ and $C$ are in reduced row-echelon form.  Recall that a pivot column is all zeros, except a single one.  More carefully, if $R$ is a matrix in reduced row-echelon form, and $d_\ell$ is the index of a pivot column, then $\matrixentry{R}{kd_\ell}=1$ precisely when $k=\ell$ and is otherwise zero.  Notice also that any entry of $R$ that is both below the entry in row $\ell$ <em>and</em> to the left of column $d_\ell$ is also zero (with below and left understood to include equality).  In other words, look at examples of matrices in reduced row-echelon form and choose a leading 1 (with a box around it).  The rest of the column is also zeros, and the lower left “quadrant” of the matrix that begins here is totally zeros.</p>

<p>Assuming no relationship about the form of $B$ and $C$, let $B$ have $r$ nonzero rows and denote the pivot columns as $D=\set{\scalarlist{d}{r}}$.  For $C$ let $r^\prime$ denote the number of nonzero rows and denote the pivot columns
as


$D^\prime=\set{\,\scalarlist{d^\prime}{r^\prime}}$ (<a class="knowl" acro="RREF" type="Definition" title="Reduced Row-Echelon Form" knowl="./knowls/definition.RREF.knowl">Definition RREF</a>).  There are four steps in the proof, and the first three are about showing that $B$ and $C$ have the same number of pivot columns, in the same places.  In other words, the “primed” symbols are a necessary fiction.</p>

<p>
First Step.  Suppose that $d_1&lt;d^\prime_1$.  Then
\begin{align*}
1
&amp;=\matrixentry{B}{1d_1}
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\sum_{k=1}^{m}\delta_{1k}\matrixentry{C}{kd_1}\\
&amp;=\sum_{k=1}^{m}\delta_{1k}(0)
&amp;&amp;d_1&lt;d^\prime_1\\
&amp;=0
\end{align*}

The entries of $C$ are all zero since they are left and below of the leading 1 in row 1 and column $d^\prime_1$ of $C$.  This is a contradiction, so we know that $d_1\geq d^\prime_1$.  By an entirely similar argument, reversing the roles of $B$ and $C$, we could conclude that $d_1\leq d^\prime_1$.  Together this means that $d_1=d^\prime_1$.</p>

<p>Second Step.  Suppose that we have determined that $d_1=d^\prime_1$, $d_2=d^\prime_2$, $d_3=d^\prime_3$, … $d_p=d^\prime_p$.  Let us now show that $d_{p+1}=d^\prime_{p+1}$.  Working towards a contradiction, suppose that $d_{p+1}&lt;d^\prime_{p+1}$.  For $1\leq\ell\leq p$,
\begin{align*}
0
&amp;=\matrixentry{B}{p+1,d_\ell}
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\sum_{k=1}^{m}\delta_{p+1,k}\matrixentry{C}{kd_\ell}\\
&amp;=\sum_{k=1}^{m}\delta_{p+1,k}\matrixentry{C}{kd^\prime_\ell}\\
&amp;=
\delta_{p+1,\ell}\matrixentry{C}{\ell d^\prime_\ell}+
\sum_{\substack{k=1\\k\neq\ell}}^{m}\delta_{p+1,k}\matrixentry{C}{kd^\prime_\ell}
&amp;&amp;\knowl{./knowls/property.CACN.knowl}{\text{Property CACN}}\\
&amp;=
\delta_{p+1,\ell}(1)+
\sum_{\substack{k=1\\k\neq\ell}}^{m}\delta_{p+1,k}(0)
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\delta_{p+1,\ell}
\end{align*}

Now,
\begin{align*}
1
&amp;=\matrixentry{B}{p+1,d_{p+1}}
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\sum_{k=1}^{m}\delta_{p+1,k}\matrixentry{C}{kd_{p+1}}\\
&amp;=
\sum_{k=1}^{p}\delta_{p+1,k}\matrixentry{C}{kd_{p+1}}+
\sum_{k=p+1}^{m}\delta_{p+1,k}\matrixentry{C}{kd_{p+1}}
&amp;&amp;\knowl{./knowls/property.AACN.knowl}{\text{Property AACN}}\\
&amp;=
\sum_{k=1}^{p}(0)\matrixentry{C}{kd_{p+1}}+
\sum_{k=p+1}^{m}\delta_{p+1,k}\matrixentry{C}{kd_{p+1}}\\
&amp;=\sum_{k=p+1}^{m}\delta_{p+1,k}\matrixentry{C}{kd_{p+1}}\\
&amp;=\sum_{k=p+1}^{m}\delta_{p+1,k}(0)
&amp;&amp;d_{p+1}&lt;d^\prime_{p+1}\\
&amp;=0
\end{align*}

This contradiction shows that
$d_{p+1}\geq d^\prime_{p+1}$.  By an entirely similar argument, we could conclude that $d_{p+1}\leq d^\prime_{p+1}$, and therefore $d_{p+1}=d^\prime_{p+1}$.</p>

<p>
Third Step.  Now we establish that $r=r^\prime$.  Suppose that $r^\prime&lt;r$.  By the arguments above, we know that $d_1=d^\prime_1$, $d_2=d^\prime_2$, $d_3=d^\prime_3$, …, $d_{r^\prime}=d^\prime_{r^\prime}$.   For $1\leq\ell\leq r^\prime&lt;r$,
\begin{align*}
0
&amp;=\matrixentry{B}{rd_\ell}
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\sum_{k=1}^{m}\delta_{rk}\matrixentry{C}{kd_\ell}\\
&amp;=
\sum_{k=1}^{r^\prime}\delta_{rk}\matrixentry{C}{kd_\ell}
+
\sum_{k=r^\prime+1}^{m}\delta_{rk}\matrixentry{C}{kd_\ell}
&amp;&amp;\knowl{./knowls/property.AACN.knowl}{\text{Property AACN}}\\%
&amp;=
\sum_{k=1}^{r^\prime}\delta_{rk}\matrixentry{C}{kd_\ell}
+
\sum_{k=r^\prime+1}^{m}\delta_{rk}(0)
&amp;&amp;\knowl{./knowls/property.AACN.knowl}{\text{Property AACN}}\\
&amp;=\sum_{k=1}^{r^\prime}\delta_{rk}\matrixentry{C}{kd_\ell}\\
&amp;=\sum_{k=1}^{r^\prime}\delta_{rk}\matrixentry{C}{kd^\prime_\ell}\\
&amp;=
\delta_{r\ell}\matrixentry{C}{\ell d^\prime_\ell}
+
\sum_{\substack{k=1\\k\neq\ell}}^{r^\prime}\delta_{rk}\matrixentry{C}{kd^\prime_\ell}
&amp;&amp;\knowl{./knowls/property.CACN.knowl}{\text{Property CACN}}\\
&amp;=
\delta_{r\ell}(1)
+
\sum_{\substack{k=1\\k\neq\ell}}^{r^\prime}\delta_{rk}(0)
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\delta_{r\ell}
\end{align*}

Now examine the entries of row $r$ of $B$,
\begin{align*}
\matrixentry{B}{rj}
&amp;=\sum_{k=1}^{m}\delta_{rk}\matrixentry{C}{kj}\\
&amp;=
\sum_{k=1}^{r^\prime}\delta_{rk}\matrixentry{C}{kj}
+
\sum_{k=r^\prime+1}^{m}\delta_{rk}\matrixentry{C}{kj}
&amp;&amp;\knowl{./knowls/property.CACN.knowl}{\text{Property CACN}}\\
&amp;=
\sum_{k=1}^{r^\prime}\delta_{rk}\matrixentry{C}{kj}
+
\sum_{k=r^\prime+1}^{m}\delta_{rk}(0)
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\sum_{k=1}^{r^\prime}\delta_{rk}\matrixentry{C}{kj}\\
&amp;=\sum_{k=1}^{r^\prime}(0)\matrixentry{C}{kj}\\
&amp;=0
\end{align*}

So row $r$ is a totally zero row, contradicting that this should be the bottommost nonzero row of $B$.  So $r^\prime\geq r$.  By an entirely similar argument, reversing the roles of $B$ and $C$, we would conclude that $r^\prime\leq r$ and therefore $r=r^\prime$.  Thus, combining the first three steps we can say that $D=D^\prime$.  In other words, $B$ and $C$ have the same pivot columns, in the same locations.</p>

<p>
Fourth Step.  In this final step, we will not argue by contradiction.  Our intent is to determine the values of the $\delta_{ij}$.  Notice that we can use the values of the $d_i$ interchangeably for $B$ and $C$.  Here we go,
\begin{align*}
1
&amp;=\matrixentry{B}{id_i}
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\sum_{k=1}^{m}\delta_{ik}\matrixentry{C}{kd_i}\\
&amp;=
\delta_{ii}\matrixentry{C}{id_i}
+
\sum_{\substack{k=1\\k\neq i}}^{m}\delta_{ik}\matrixentry{C}{kd_i}
&amp;&amp;\knowl{./knowls/property.CACN.knowl}{\text{Property CACN}}\\
&amp;=
\delta_{ii}(1)
+
\sum_{\substack{k=1\\k\neq i}}^{m}\delta_{ik}(0)
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\delta_{ii}
\end{align*}

and for $\ell\neq i$
\begin{align*}
0
&amp;=\matrixentry{B}{id_\ell}
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\sum_{k=1}^{m}\delta_{ik}\matrixentry{C}{kd_\ell}\\
&amp;=
\delta_{i\ell}\matrixentry{C}{\ell d_\ell}
+
\sum_{\substack{k=1\\k\neq\ell}}^{m}\delta_{ik}\matrixentry{C}{kd_\ell}
&amp;&amp;\knowl{./knowls/property.CACN.knowl}{\text{Property CACN}}\\
&amp;=
\delta_{i\ell}(1)
+
\sum_{\substack{k=1\\k\neq\ell}}^{m}\delta_{ik}(0)
&amp;&amp;\knowl{./knowls/definition.RREF.knowl}{\text{Definition RREF}}\\
&amp;=\delta_{i\ell}
\end{align*}

Finally, having determined the values of the $\delta_{ij}$, we can show that $B=C$.  For $1\leq i\leq m$, $1\leq j\leq n$,
\begin{align*}
\matrixentry{B}{ij}
&amp;=\sum_{k=1}^{m}\delta_{ik}\matrixentry{C}{kj}\\
&amp;=
\delta_{ii}\matrixentry{C}{ij}
+
\sum_{\substack{k=1\\k\neq i}}^{m}\delta_{ik}\matrixentry{C}{kj}
&amp;&amp;\knowl{./knowls/property.CACN.knowl}{\text{Property CACN}}\\
&amp;=
(1)\matrixentry{C}{ij}
+
\sum_{\substack{k=1\\k\neq i}}^{m}(0)\matrixentry{C}{kj}\\
&amp;=\matrixentry{C}{ij}
\end{align*}

So $B$ and $C$ have equal values in every entry, and so are the same matrix.</p>

</div>
