<div class="proof" id="proof-ME" acro="ME" titletext="">
<h5 class="proof">
<span class="type">Proof of Theorem</span> <span class="acro">ME</span>
</h5>
<p>Since $\lambda$ is an eigenvalue of $A$, there is an eigenvector of $A$ for $\lambda$, $\vect{x}$.  Then $\vect{x}\in\eigenspace{A}{\lambda}$, so $\geomult{A}{\lambda}\geq 1$, since we can extend $\set{\vect{x}}$ into a basis of $\eigenspace{A}{\lambda}$ (<a class="knowl" acro="ELIS" type="Theorem" title="Extending Linearly Independent Sets" knowl="./knowls/theorem.ELIS.knowl">Theorem ELIS</a>).</p>

<p>To show $\geomult{A}{\lambda}\leq\algmult{A}{\lambda}$ is the most involved portion of this proof.  To this end, let $g=\geomult{A}{\lambda}$ and let $\vectorlist{x}{g}$ be a basis for the eigenspace of $\lambda$, $\eigenspace{A}{\lambda}$.  Construct another $n-g$ vectors, $\vectorlist{y}{n-g}$, so that
\begin{equation*}
\set{\vectorlist{x}{g},\,\vectorlist{y}{n-g}}
\end{equation*}
is a basis of $\complex{n}$.  This can be done by repeated applications of <a class="knowl" acro="ELIS" type="Theorem" title="Extending Linearly Independent Sets" knowl="./knowls/theorem.ELIS.knowl">Theorem ELIS</a>.</p>

<p>Finally, define a matrix $S$ by
\begin{equation*}
S=[\vect{x}_1|\vect{x}_2|\vect{x}_3|\ldots|\vect{x}_g|\vect{y}_1|\vect{y}_2|\vect{y}_3|\ldots|\vect{y}_{n-g}]
=[\vect{x}_1|\vect{x}_2|\vect{x}_3|\ldots|\vect{x}_g|R]
\end{equation*}
where $R$ is an $n\times(n-g)$ matrix whose columns are $\vectorlist{y}{n-g}$.  The columns of $S$ are linearly independent by design, so $S$ is nonsingular (<a class="knowl" acro="NMLIC" type="Theorem" title="Nonsingular Matrices have Linearly Independent Columns" knowl="./knowls/theorem.NMLIC.knowl">Theorem NMLIC</a>) and therefore invertible (<a class="knowl" acro="NI" type="Theorem" title="Nonsingularity is Invertibility" knowl="./knowls/theorem.NI.knowl">Theorem NI</a>).</p>

<p>Then,
\begin{align*}
\matrixcolumns{e}{n}&amp;=I_n\\
&amp;=\inverse{S}S\\
&amp;=\inverse{S}[\vect{x}_1|\vect{x}_2|\vect{x}_3|\ldots|\vect{x}_g|R]\\
&amp;=[\inverse{S}\vect{x}_1|\inverse{S}\vect{x}_2|\inverse{S}\vect{x}_3|\ldots|\inverse{S}\vect{x}_g|\inverse{S}R]
\end{align*}

</p>

<p>So
\begin{equation*}
\inverse{S}\vect{x}_i=\vect{e}_i\quad 1\leq i\leq g\tag{$*$}
\end{equation*}
</p>

<p>Preparations in place, we compute the characteristic polynomial of $A$,
\begin{align*}
\charpoly{A}{x}&amp;=\detname{A-xI_n}&amp;&amp;\knowl{./knowls/definition.CP.knowl}{\text{Definition CP}}\\
&amp;=1\detname{A-xI_n}&amp;&amp;\knowl{./knowls/property.OCN.knowl}{\text{Property OCN}}\\
&amp;=\detname{I_n}\detname{A-xI_n}&amp;&amp;\knowl{./knowls/definition.DM.knowl}{\text{Definition DM}}\\
&amp;=\detname{\inverse{S}S}\detname{A-xI_n}&amp;&amp;\knowl{./knowls/definition.MI.knowl}{\text{Definition MI}}\\
&amp;=\detname{\inverse{S}}\detname{S}\detname{A-xI_n}&amp;&amp;\knowl{./knowls/theorem.DRMM.knowl}{\text{Theorem DRMM}}\\
&amp;=\detname{\inverse{S}}\detname{A-xI_n}\detname{S}&amp;&amp;\knowl{./knowls/property.CMCN.knowl}{\text{Property CMCN}}\\
&amp;=\detname{\inverse{S}\left(A-xI_n\right)S}&amp;&amp;\knowl{./knowls/theorem.DRMM.knowl}{\text{Theorem DRMM}}\\
&amp;=\detname{\inverse{S}AS-\inverse{S}xI_nS}&amp;&amp;\knowl{./knowls/theorem.MMDAA.knowl}{\text{Theorem MMDAA}}\\
&amp;=\detname{\inverse{S}AS-x\inverse{S}I_nS}&amp;&amp;\knowl{./knowls/theorem.MMSMM.knowl}{\text{Theorem MMSMM}}\\
&amp;=\detname{\inverse{S}AS-x\inverse{S}S}&amp;&amp;\knowl{./knowls/theorem.MMIM.knowl}{\text{Theorem MMIM}}\\
&amp;=\detname{\inverse{S}AS-xI_n}&amp;&amp;\knowl{./knowls/definition.MI.knowl}{\text{Definition MI}}\\
&amp;=\charpoly{\inverse{S}AS}{x}&amp;&amp;\knowl{./knowls/definition.CP.knowl}{\text{Definition CP}}
\end{align*}

</p>

<p>What can we learn then about the matrix $\inverse{S}AS$?
\begin{align*}
\inverse{S}AS&amp;=\inverse{S}A[\vect{x}_1|\vect{x}_2|\vect{x}_3|\ldots|\vect{x}_g|R]\\
&amp;=\inverse{S}[A\vect{x}_1|A\vect{x}_2|A\vect{x}_3|\ldots|A\vect{x}_g|AR]&amp;&amp;\knowl{./knowls/definition.MM.knowl}{\text{Definition MM}}\\
&amp;=\inverse{S}[\lambda\vect{x}_1|\lambda\vect{x}_2|\lambda\vect{x}_3|\ldots|\lambda\vect{x}_g|AR]&amp;&amp;\knowl{./knowls/definition.EEM.knowl}{\text{Definition EEM}}\\
&amp;=[\inverse{S}\lambda\vect{x}_1|\inverse{S}\lambda\vect{x}_2|\inverse{S}\lambda\vect{x}_3|\ldots|\inverse{S}\lambda\vect{x}_g|\inverse{S}AR]&amp;&amp;\knowl{./knowls/definition.MM.knowl}{\text{Definition MM}}\\
&amp;=[\lambda\inverse{S}\vect{x}_1|\lambda\inverse{S}\vect{x}_2|\lambda\inverse{S}\vect{x}_3|\ldots|\lambda\inverse{S}\vect{x}_g|\inverse{S}AR]&amp;&amp;\knowl{./knowls/theorem.MMSMM.knowl}{\text{Theorem MMSMM}}\\
&amp;=[\lambda\vect{e}_1|\lambda\vect{e}_2|\lambda\vect{e}_3|\ldots|\lambda\vect{e}_g|\inverse{S}AR]&amp;&amp;\text{$\inverse{S}S=I_n$, (($*$) above)}
\end{align*}

</p>

<p>Now imagine computing the characteristic polynomial of $A$ by computing the characteristic polynomial of $\inverse{S}AS$ using the form just obtained.  The first $g$ columns of $\inverse{S}AS$ are all zero, save for a $\lambda$ on the diagonal.  So if we compute the determinant by expanding about the first column, successively, we will get successive factors of $(\lambda-x)$.  More precisely, let $T$ be the square matrix of size $n-g$ that is formed from the last $n-g$ rows and last $n-g$ columns of $\inverse{S}AR$.  Then
\begin{equation*}
\charpoly{A}{x}=\charpoly{\inverse{S}AS}{x}=(\lambda-x)^g\charpoly{T}{x}.
\end{equation*}
</p>

<p>This says that $(x-\lambda)$ is a factor of the characteristic polynomial <em>at least</em> $g$ times, so the algebraic multiplicity of $\lambda$ as an eigenvalue of $A$ is greater than or equal to $g$ (<a class="knowl" acro="AME" type="Definition" title="Algebraic Multiplicity of an Eigenvalue" knowl="./knowls/definition.AME.knowl">Definition AME</a>).  In other words,
\begin{equation*}
\geomult{A}{\lambda}=g\leq\algmult{A}{\lambda}
\end{equation*}
as desired.</p>

<p><a class="knowl" acro="NEM" type="Theorem" title="Number of Eigenvalues of a Matrix" knowl="./knowls/theorem.NEM.knowl">Theorem NEM</a> says that the sum of the algebraic multiplicities for <em>all</em> the eigenvalues of $A$ is equal to $n$.  Since the algebraic multiplicity is a positive quantity, no single algebraic multiplicity can exceed $n$ without the sum of all of the algebraic multiplicities doing the same.</p>

</div>
