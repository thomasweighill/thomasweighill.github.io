<div class="proof" id="proof-EMHE" acro="EMHE" titletext="">
<h5 class="proof">
<span class="type">Proof of Theorem</span> <span class="acro">EMHE</span>
</h5>
<p>Suppose that $A$ has size $n$, and choose $\vect{x}$ as <em>any</em> nonzero vector from $\complex{n}$.  (Notice how much latitude we have in our choice of $\vect{x}$.  Only the zero vector is off-limits.)  Consider the set
\begin{equation*}
S=\set{\vect{x},\,A\vect{x},\,A^2\vect{x},\,A^3\vect{x},\,\ldots,\,A^n\vect{x}}
\end{equation*}
</p>

<p>This is a set of $n+1$ vectors from $\complex{n}$, so by <a class="knowl" acro="MVSLD" type="Theorem" title="More Vectors than Size implies Linear Dependence" knowl="./knowls/theorem.MVSLD.knowl">Theorem MVSLD</a>, $S$ is linearly dependent.  Let $a_0,\,a_1,\,a_2,\,\ldots,\,a_n$ be a collection of $n+1$ scalars from $\complex{\null}$, not all zero, that provide a relation of linear dependence on $S$.  In other words,
\begin{equation*}
a_0\vect{x}+a_1A\vect{x}+a_2A^2\vect{x}+a_3A^3\vect{x}+\cdots+a_nA^n\vect{x}=\zerovector
\end{equation*}
</p>

<p>Some of the $a_i$ are nonzero.  Suppose that just $a_0\neq 0$, and $a_1=a_2=a_3=\cdots=a_n=0$.  Then $a_0\vect{x}=\zerovector$ and by <a class="knowl" acro="SMEZV" type="Theorem" title="Scalar Multiplication Equals the Zero Vector" knowl="./knowls/theorem.SMEZV.knowl">Theorem SMEZV</a>, either $a_0=0$ or $\vect{x}=\zerovector$, which are both contradictions.  So $a_i\neq 0$ for some $i\geq 1$.  Let $m$ be the largest integer such that $a_m\neq 0$.  From this discussion we know that $m\geq 1$.  We can also assume that $a_m=1$, for if not, replace each $a_i$ by $a_i/a_m$ to obtain scalars that serve equally well in providing a relation of linear dependence on $S$.</p>

<p>Define the polynomial
\begin{equation*}
p(x)=a_0+a_1x+a_2x^2+a_3x^3+\cdots+a_mx^m
\end{equation*}
</p>

<p>Because we have consistently used $\complex{\null}$ as our set of scalars (rather than ${\mathbb R}$), we know that we can factor $p(x)$ into linear factors of the form $(x-b_i)$, where $b_i\in\complex{\null}$.  So there are scalars, $\scalarlist{b}{m}$, from $\complex{\null}$ so that,
\begin{equation*}
p(x)=(x-b_m)(x-b_{m-1})\cdots(x-b_3)(x-b_2)(x-b_1)
\end{equation*}
</p>

<p>Put it all together and
\begin{align*}
\zerovector&amp;=a_0\vect{x}+a_1A\vect{x}+a_2A^2\vect{x}+\cdots+a_nA^n\vect{x}\\
&amp;=a_0\vect{x}+a_1A\vect{x}+a_2A^2\vect{x}+\cdots+a_mA^m\vect{x}&amp;&amp;\text{$a_i=0$ for $i&gt;m$}\\
&amp;=\left(a_0I_n+a_1A+a_2A^2+\cdots+a_mA^m\right)\vect{x}&amp;&amp;\knowl{./knowls/theorem.MMDAA.knowl}{\text{Theorem MMDAA}}\\
&amp;=p(A)\vect{x}&amp;&amp;\text{Definition of $p(x)$}\\
&amp;=(A-b_mI_n)(A-b_{m-1}I_n)\cdots(A-b_2I_n)(A-b_1I_n)\vect{x}
\end{align*}

</p>

<p>Let $k$ be the smallest integer such that
\begin{equation*}
(A-b_kI_n)(A-b_{k-1}I_n)\cdots(A-b_2I_n)(A-b_1I_n)\vect{x}=\zerovector.
\end{equation*}
</p>

<p>From the preceding equation, we know that $k\leq m$.  Define the vector $\vect{z}$ by
\begin{equation*}
\vect{z}=(A-b_{k-1}I_n)\cdots(A-b_2I_n)(A-b_1I_n)\vect{x}
\end{equation*}
</p>

<p>Notice that by the definition of $k$, the vector $\vect{z}$ must be nonzero.  In the case where $k=1$, we understand that $\vect{z}$ is defined by $\vect{z}=\vect{x}$, and $\vect{z}$ is still nonzero.  Now
\begin{equation*}
(A-b_kI_n)\vect{z}=(A-b_kI_n)(A-b_{k-1}I_n)\cdots(A-b_3I_n)(A-b_2I_n)(A-b_1I_n)\vect{x}=\zerovector
\end{equation*}
which allows us to write
\begin{align*}
A\vect{z}
&amp;=(A+\zeromatrix)\vect{z}&amp;&amp;\knowl{./knowls/property.ZM.knowl}{\text{Property ZM}}\\
&amp;=(A-b_kI_n+b_kI_n)\vect{z}&amp;&amp;\knowl{./knowls/property.AIM.knowl}{\text{Property AIM}}\\
&amp;=(A-b_kI_n)\vect{z}+b_kI_n\vect{z}&amp;&amp;\knowl{./knowls/theorem.MMDAA.knowl}{\text{Theorem MMDAA}}\\
&amp;=\zerovector+b_kI_n\vect{z}&amp;&amp;\text{Defining property of $\vect{z}$}\\
&amp;=b_kI_n\vect{z}&amp;&amp;\knowl{./knowls/property.ZM.knowl}{\text{Property ZM}}\\
&amp;=b_k\vect{z}&amp;&amp;\knowl{./knowls/theorem.MMIM.knowl}{\text{Theorem MMIM}}
\end{align*}

</p>

<p>Since $\vect{z}\neq\zerovector$, this equation says that $\vect{z}$ is an eigenvector of $A$ for the eigenvalue $\lambda=b_k$ (<a class="knowl" acro="EEM" type="Definition" title="Eigenvalues and Eigenvectors of a Matrix" knowl="./knowls/definition.EEM.knowl">Definition EEM</a>), so we have shown that any square matrix $A$ does have at least one eigenvalue.</p>

</div>
