<div class="subsection" id="subsection-GSP" acro="GSP" titletext="Gram-Schmidt Procedure">
<h4 class="subsection">
<span class="type">Subsection</span> <span class="acro">GSP</span> <span class="titletext">Gram-Schmidt Procedure</span>
</h4>
<p>The Gram-Schmidt Procedure is really a theorem.  It says that if we begin with a linearly independent set of $p$ vectors, $S$, then we can do a number of calculations with these vectors and produce an orthogonal set of $p$ vectors, $T$, so that $\spn{S}=\spn{T}$.  Given the large number of computations involved, it is indeed a procedure to do all the necessary computations, and it is best employed on a computer.  However, it also has value in proofs where we may on occasion wish to replace a linearly independent set by an orthogonal set.</p>
<p>This is our first occasion to use the technique of “mathematical induction” for a proof, a technique we will see again several times, especially in <a href="chapter-D.html" title="Determinants">Chapter D</a>.  So study the simple example described in <a class="knowl" acro="I" type="Proof Technique" title="Induction" knowl="./knowls/technique.I.knowl">Proof Technique I</a> first.</p>
<div class="theorem" id="theorem-GSP" acro="GSP" titletext="Gram-Schmidt Procedure">
<h5 class="theorem">
<span class="type">Theorem </span><span class="acro">GSP</span><span class="titletext"> Gram-Schmidt Procedure</span>
</h5>
<div class="statement">
<p>Suppose that $S=\set{\vectorlist{v}{p}}$ is a linearly independent set of vectors in $\complex{m}$.  Define the vectors $\vect{u}_i$, $1\leq i\leq p$ by
\begin{equation*}
\vect{u}_i=\vect{v}_i
-\frac{\innerproduct{\vect{u}_1}{\vect{v}_i}}{\innerproduct{\vect{u}_1}{\vect{u}_1}}\vect{u}_1
-\frac{\innerproduct{\vect{u}_2}{\vect{v}_i}}{\innerproduct{\vect{u}_2}{\vect{u}_2}}\vect{u}_2
-\frac{\innerproduct{\vect{u}_3}{\vect{v}_i}}{\innerproduct{\vect{u}_3}{\vect{u}_3}}\vect{u}_3
-\cdots
-\frac{\innerproduct{\vect{u}_{i-1}}{\vect{v}_i}}{\innerproduct{\vect{u}_{i-1}}{\vect{u}_{i-1}}}\vect{u}_{i-1}
\end{equation*}</p>
<p>Let $T=\set{\vectorlist{u}{p}}$.  Then $T$ is an orthogonal set of nonzero vectors, and $\spn{T}=\spn{S}$.</p>
</div>
<div class="proof"><a knowl="./knowls/proof.GSP.knowl">Proof</a></div>
</div>
<div class="example" id="example-GSTV" acro="GSTV" titletext="Gram-Schmidt of three vectors"><h5 class="example">
<a knowl="./knowls/example.GSTV.knowl"><span class="type">Example</span> <span class="acro">GSTV</span></a> <span class="titletext">Gram-Schmidt of three vectors</span>
</h5></div>
<p>One final definition related to orthogonal vectors.</p>
<div class="definition" id="definition-ONS" acro="ONS" titletext="OrthoNormal Set">
<h5 class="definition">
<span class="type">Definition </span><span class="acro">ONS</span> <span class="titletext"> OrthoNormal Set</span>
</h5>
<p>Suppose $S=\set{\vectorlist{u}{n}}$ is an orthogonal set of vectors such that $\norm{\vect{u}_i}=1$ for all $1\leq i\leq n$.  Then $S$ is an <em class="term">orthonormal</em> set of vectors.</p>
</div>
<p>Once you have an orthogonal set, it is easy to convert it to an orthonormal set — multiply each vector by the reciprocal of its norm, and the resulting vector will have norm 1.  This scaling of each vector will not affect the orthogonality properties (apply <a class="knowl" acro="IPSM" type="Theorem" title="Inner Product and Scalar Multiplication" knowl="./knowls/theorem.IPSM.knowl">Theorem IPSM</a>).</p>
<div class="example" id="example-ONTV" acro="ONTV" titletext="Orthonormal set, three vectors"><h5 class="example">
<a knowl="./knowls/example.ONTV.knowl"><span class="type">Example</span> <span class="acro">ONTV</span></a> <span class="titletext">Orthonormal set, three vectors</span>
</h5></div>
<div class="example" id="example-ONFV" acro="ONFV" titletext="Orthonormal set, four vectors"><h5 class="example">
<a knowl="./knowls/example.ONFV.knowl"><span class="type">Example</span> <span class="acro">ONFV</span></a> <span class="titletext">Orthonormal set, four vectors</span>
</h5></div>
<p>We will see orthonormal sets again in <a class="knowl" acro="MINM.UM" type="Subsection" title="" knowl="./knowls/subsection.MINM.UM.knowl">Subsection MINM.UM</a>.   They are intimately related to unitary matrices (<a class="knowl" acro="UM" type="Definition" title="Unitary Matrices" knowl="./knowls/definition.UM.knowl">Definition UM</a>) through <a class="knowl" acro="CUMOS" type="Theorem" title="Columns of Unitary Matrices are Orthonormal Sets" knowl="./knowls/theorem.CUMOS.knowl">Theorem CUMOS</a>.  Some of the utility of orthonormal sets is captured by <a class="knowl" acro="COB" type="Theorem" title="Coordinates and Orthonormal Bases" knowl="./knowls/theorem.COB.knowl">Theorem COB</a> in <a class="knowl" acro="B.OBC" type="Subsection" title="" knowl="./knowls/subsection.B.OBC.knowl">Subsection B.OBC</a>.   Orthonormal sets appear once again in <a href="section-OD.html" title="Orthonormal Diagonalization">Section OD</a> where they are key in orthonormal diagonalization.</p>
<div class="sage" id="sage-OGS" acro="OGS" titletext="Orthogonality and Gram-Schmidt"><h5 class="sage">
<a knowl="./knowls/sage.OGS.knowl"><span class="type">Sage</span> <span class="acro">OGS</span></a> <span class="titletext">Orthogonality and Gram-Schmidt</span>
</h5></div>
</div><div class="context"><a href="http://linear.pugetsound.edu/html/section-O.html#subsection-GSP" class="context" title="Section O">(in context)</a></div>
