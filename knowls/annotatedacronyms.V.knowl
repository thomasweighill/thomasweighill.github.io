<div class="annotatedacronyms" id="annotatedacronyms-V" acro="V" titletext="">
<h5 class="annotatedacronyms">
<span class="type">Annotated Acronyms for Chapter</span> <span class="acro">V</span>
</h5>
<div class="annoacro"><h5 class="annoacro"><a class="knowl" acro="VSPCV" type="Theorem" title="Vector Space Properties of Column Vectors" knowl="./knowls/theorem.VSPCV.knowl">Theorem VSPCV</a></h5></div>
<p>
These are the fundamental rules for working with the addition, and scalar multiplication, of column vectors.  We will see something very similar in the next chapter (<a class="knowl" acro="VSPM" type="Theorem" title="Vector Space Properties of Matrices" knowl="./knowls/theorem.VSPM.knowl">Theorem VSPM</a>) and then this will be generalized into what is arguably our most important definition, <a class="knowl" acro="VS" type="Definition" title="Vector Space" knowl="./knowls/definition.VS.knowl">Definition VS</a>.
</p>
<div class="annoacro"><h5 class="annoacro"><a class="knowl" acro="SLSLC" type="Theorem" title="Solutions to Linear Systems are Linear Combinations" knowl="./knowls/theorem.SLSLC.knowl">Theorem SLSLC</a></h5></div>
<p>
Vector addition and scalar multiplication are the two fundamental operations on vectors, and linear combinations roll them both into one.  <a class="knowl" acro="SLSLC" type="Theorem" title="Solutions to Linear Systems are Linear Combinations" knowl="./knowls/theorem.SLSLC.knowl">Theorem SLSLC</a> connects linear combinations with systems of equations.  This one we will see often enough that it is worth memorizing.
</p>
<div class="annoacro"><h5 class="annoacro"><a class="knowl" acro="PSPHS" type="Theorem" title="Particular Solution Plus Homogeneous Solutions" knowl="./knowls/theorem.PSPHS.knowl">Theorem PSPHS</a></h5></div>
<p>
This theorem is interesting in its own right, and sometimes the vaugeness surrounding the choice of $\vect{z}$ can seem mysterious.  But we list it here because we will see an important theorem in <a href="section-ILT.html" title="Injective Linear Transformations">Section ILT</a> which will generalize this result (<a class="knowl" acro="KPI" type="Theorem" title="Kernel and Pre-Image" knowl="./knowls/theorem.KPI.knowl">Theorem KPI</a>).
</p>
<div class="annoacro"><h5 class="annoacro"><a class="knowl" acro="LIVRN" type="Theorem" title="Linearly Independent Vectors, $r$ and $n$" knowl="./knowls/theorem.LIVRN.knowl">Theorem LIVRN</a></h5></div>
<p>
If you have a set of column vectors, this is the fastest computational approach to determine if the set is linearly independent.  Make the vectors the columns of a matrix, row-reduce, compare $r$ and $n$.  That's it — and you always get an answer.  Put this one in your toolkit.
</p>
<div class="annoacro"><h5 class="annoacro"><a class="knowl" acro="BNS" type="Theorem" title="Basis for Null Spaces" knowl="./knowls/theorem.BNS.knowl">Theorem BNS</a></h5></div>
<p>
We will have several theorems (all listed in these “Annotated Acronyms” sections) whose conclusions will provide a linearly independent set of vectors whose span equals some set of interest (the null space here).  While the notation in this theorem might appear gruesome, in practice it can become very routine to apply.  So practice this one — we will be using it all through the book.
</p>
<div class="annoacro"><h5 class="annoacro"><a class="knowl" acro="BS" type="Theorem" title="Basis of a Span" knowl="./knowls/theorem.BS.knowl">Theorem BS</a></h5></div>
<p>
As promised, another theorem that provides a linearly independent set of vectors whose span equals some set of interest (a span now).  You can use this one to clean up <em>any</em> span.
</p>
</div>
